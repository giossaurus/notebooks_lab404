{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMTol0gjEezc+BBp7QTn64u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Instalação da biblioteca oficial da Mistral"],"metadata":{"id":"r8ZhvJSaFMlt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1C61ZpSUFGhD"},"outputs":[],"source":["!pip install mistralai"]},{"cell_type":"markdown","source":["Configurando a API"],"metadata":{"id":"R8yQyvUQFmTk"}},{"cell_type":"code","source":["import os\n","from mistralai import Mistral\n","\n","# Pegue sua chave em https://mistral.ai/ e cole aqui, ou defina via variável de ambiente\n","api_key = os.getenv(\"MISTRAL_API_KEY\", \"sua_chave_de_api_aqui\")\n","\n","client = Mistral(api_key=api_key)\n","MODEL_NAME = \"mistral-small-latest\"  # Ou 'mistral-medium-latest', 'mistral-large-latest'"],"metadata":{"id":"zCLYnx1VFuNT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Criando uma função para gerar respostas com controle de tokens"],"metadata":{"id":"vob04KaOFvDl"}},{"cell_type":"code","source":["def gerar_resposta(prompt, max_tokens=300, temperature=0.0):\n","    response = client.chat.complete(\n","        model=MODEL_NAME,\n","        messages=[{\"role\": \"user\", \"content\": prompt}],\n","        max_tokens=max_tokens,\n","        temperature=temperature\n","    )\n","    content = response.choices[0].message.content\n","    print(f\"Tokens usados: {response.usage.total_tokens}\")\n","    return content"],"metadata":{"id":"Rsr9E6dsF9e4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exemplo 1 - Prompt sem papel definido:"],"metadata":{"id":"zdWn8VAyF_NF"}},{"cell_type":"code","source":["prompt = \"Dê dicas de como melhorar minha comunicação.\"\n","print(gerar_resposta(prompt, max_tokens=200))\n"],"metadata":{"id":"Io1KtayaGgzU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exemplo 2 - Definindo um papel"],"metadata":{"id":"NbhRDaRMP2ox"}},{"cell_type":"code","source":["prompt = (\n","    \"Você é um coach especialista em comunicação assertiva. \"\n","    \"Dê 5 dicas práticas para melhorar a comunicação no ambiente de trabalho. \"\n","    \"Formato da resposta:\\n\"\n","    \"1. ...\\n\"\n","    \"2. ...\\n\"\n","    \"3. ...\\n\"\n","    \"4. ...\\n\"\n","    \"5. ...\"\n",")\n","\n","print(gerar_resposta(prompt, max_tokens=300))"],"metadata":{"id":"UXd5lgm3GoCi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exemplo 3 - Simulando um Personagem (Role Playing)"],"metadata":{"id":"AEADHnpyGrQu"}},{"cell_type":"code","source":["prompt = (\n","    \"Você é um chef francês renomado. Explique como fazer um omelete perfeito, \"\n","    \"incluindo detalhes sobre a escolha dos ingredientes e o ponto ideal de cozimento.\"\n",")\n","\n","print(gerar_resposta(prompt, max_tokens=300))\n"],"metadata":{"id":"iIfIZMiNGt-D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Teste de limites da API com roleplaying"],"metadata":{"id":"CBwQxOGKQCQA"}},{"cell_type":"code","source":["import time\n","\n","prompts = [\n","    \"Você é um personal trainer. Dê um treino rápido para iniciantes.\",\n","    \"Você é um historiador. Conte um fato curioso sobre o Egito Antigo.\",\n","    \"Você é um economista. Explique inflação para uma criança.\",\n","    \"Você é um poeta. Escreva um haicai sobre o outono.\"\n","]\n","\n","for i, prompt in enumerate(prompts):\n","    print(f\"Requisição {i+1}\")\n","    try:\n","        print(gerar_resposta(prompt, max_tokens=150))\n","    except Exception as e:\n","        print(f\"Erro ou limite atingido: {e}\")\n","    time.sleep(0.5)"],"metadata":{"id":"Tiy_6-AdQGK3"},"execution_count":null,"outputs":[]}]}